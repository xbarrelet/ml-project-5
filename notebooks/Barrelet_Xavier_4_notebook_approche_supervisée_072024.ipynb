{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-02 17:16:48.557098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-02 17:16:48.611503: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-02 17:16:48.627455: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-02 17:16:48.725273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-02 17:16:49.816118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gensim.parsing.preprocessing as gsp\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from mlflow.models import infer_signature\n",
    "from nltk import WordNetLemmatizer, PorterStemmer\n",
    "from pandas import DataFrame\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import *\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MISC CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "NUMBER_OF_QUESTIONS_USED_IN_TRAINING = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHED_QUESTIONS_FILE = '../cached_questions.json'\n",
    "MODELS_PATH = '../inferring_api/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid having multiprocessing issues between BERT and the GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cached_questions():\n",
    "    \"\"\"Load questions from the cache file.\"\"\"\n",
    "    with open(CACHED_QUESTIONS_FILE, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_saved_model():\n",
    "    \"\"\"Removes the content of the saved model.\"\"\"\n",
    "    shutil.rmtree(MODELS_PATH, ignore_errors=True)\n",
    "    os.makedirs(MODELS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_clean_text(question: dict):\n",
    "    \"\"\"Create a new 'text' field for each question containing the cleaned, tokenized and lemmatized title + body.\"\"\"\n",
    "    title = question['title']\n",
    "    body = question['body']\n",
    "    text = f\"{title} {body}\"\n",
    "    \n",
    "    for filter in [gsp.strip_tags,\n",
    "                   gsp.strip_punctuation,\n",
    "                   gsp.strip_multiple_whitespaces,\n",
    "                   gsp.strip_numeric,\n",
    "                   gsp.remove_stopwords,\n",
    "                   gsp.strip_short,\n",
    "                   gsp.lower_to_unicode]:\n",
    "        text = filter(text)\n",
    "        \n",
    "    tokenized_text = nltk.tokenize.word_tokenize(text)\n",
    "\n",
    "    # words_stemmed = (stemmer.stem(w) for w in words_without_short_words)\n",
    "    words_lemmatized = [lemmatizer.lemmatize(w) for w in tokenized_text]\n",
    "    question['text'] = \" \".join(words_lemmatized)\n",
    "\n",
    "    # bigrams = nltk.bigrams(tokenized_text)\n",
    "    # question['bigrams'] = [' '.join(bigram) for bigram in bigrams]\n",
    "\n",
    "    # trigrams = nltk.trigrams(tokenized_text)\n",
    "    # question['trigrams'] = [' '.join(trigram) for trigram in trigrams]\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_inp_fct(sentences, bert_tokenizer, max_length):\n",
    "    \"\"\"Returns BERT variables for its prediction.\"\"\"\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_mask = []\n",
    "    bert_inp_tot = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens=True,\n",
    "                                              max_length=max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask=True,\n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "        \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0],\n",
    "                             bert_inp['token_type_ids'][0],\n",
    "                             bert_inp['attention_mask'][0]))\n",
    "        \n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_using_BERT(model, model_type, sentences, max_length, b_size):\n",
    "    \"\"\"Transform the text of the question's body and title into BERT embeddings.\"\"\"\n",
    "    # We don't want to use the cleaned text field with BERT, only title + \" \" + body\n",
    "    sentences = [f\"{sentence[1]} {sentence[0]}\" for sentence in sentences.iterrows()]\n",
    "    \n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    \n",
    "    time1 = time.time()\n",
    "    for step in range(len(sentences) // batch_size):\n",
    "        idx = step * batch_size\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx + batch_size],\n",
    "                                                                               bert_tokenizer, max_length)\n",
    "        outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "        \n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        if step == 0:\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "        else:\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot, last_hidden_states))\n",
    "            \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    \n",
    "    time2 = np.round(time.time() - time1, 0)\n",
    "    print(f\"BERT processing time:{time2}s\\n\")\n",
    "    \n",
    "    return features_bert, time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_using_USE(sentences, b_size):\n",
    "    \"\"\"Transform the text of the question's body and title into USE embeddings.\"\"\"\n",
    "    # We don't want to use the cleaned text field with USE, only title + \" \" + body\n",
    "    sentences = [f\"{sentence[1]} {sentence[0]}\" for sentence in sentences.iterrows()]\n",
    "    \n",
    "    batch_size = b_size\n",
    "    time1 = time.time()\n",
    "    \n",
    "    us_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "    \n",
    "    for step in range(len(sentences) // batch_size):\n",
    "        idx = step * batch_size\n",
    "        feat = us_encoder(sentences[idx:idx + batch_size])\n",
    "        \n",
    "        if step == 0:\n",
    "            features = feat\n",
    "        else:\n",
    "            features = np.concatenate((features, feat))\n",
    "            \n",
    "    time2 = np.round(time.time() - time1, 0)\n",
    "    print(f\"USE processing time:{time2}s\\n\")\n",
    "    \n",
    "    return features, time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(questions_without_tags, text_transformation_method):\n",
    "    \"\"\"Transform the question text/body and title into words embeddings.\"\"\"\n",
    "    if text_transformation_method == \"Doc2VEC\":\n",
    "        return transform_text_using_Doc2VEC(questions_without_tags[\"text\"])\n",
    "        \n",
    "    elif text_transformation_method == \"BERT\":\n",
    "        max_length = 64\n",
    "        batch_size = 10\n",
    "        model_type = 'bert-base-uncased'\n",
    "        model = TFAutoModel.from_pretrained(model_type)\n",
    "        \n",
    "        return transform_text_using_BERT(model, model_type, questions_without_tags, max_length, batch_size)\n",
    "        \n",
    "    elif text_transformation_method == \"USE\":\n",
    "        batch_size = 10\n",
    "        return transform_text_using_USE(questions_without_tags, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text_using_Doc2VEC(questions_without_tags):\n",
    "    \"\"\"Transform the text of the question's body and title into Doc2VEC embeddings.\"\"\"\n",
    "    time1 = time.time()\n",
    "    tagged_text = [TaggedDocument(words=text, tags=[str(index)])\n",
    "                   for index, text in enumerate(questions_without_tags)]\n",
    "\n",
    "    # dm=0 for DBOW, dm=1 for PV-DM\n",
    "    model = Doc2Vec(vector_size=30, min_count=2, epochs=80, dm=0)\n",
    "    model.build_vocab(tagged_text)\n",
    "    \n",
    "    model.train(tagged_text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    embedded_text = [model.infer_vector(text.split(\" \")) for text in questions_without_tags]\n",
    "    \n",
    "    time2 = np.round(time.time() - time1, 0)\n",
    "    print(f\"Doc2VEC processing time:{time2}s\\n\")\n",
    "    \n",
    "    return embedded_text, time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_plot(results):\n",
    "    \"\"\"Generate the plot showing the performances with each words embedding method for the Jaccard Score and Hamming Loss.\"\"\"\n",
    "    results.sort_values(f\"jaccard_score\", ascending=False, inplace=True)\n",
    "    performance_plot = (results[[\"jaccard_score\", \"words_embedding_method\"]]\n",
    "                        .plot(kind=\"bar\", x=\"words_embedding_method\", figsize=(15, 8), rot=0,\n",
    "                                    title=\"Models Performance Sorted by Jaccard Score\"))\n",
    "    performance_plot.title.set_size(20)\n",
    "    performance_plot.set(xlabel=None)\n",
    "    # performance_plot.get_figure().savefig(f\"{RESULTS_PATH}/performance_jaccard_score_plot.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    results.sort_values(f\"hamming_loss\", ascending=True, inplace=True)\n",
    "    performance_plot = (results[[\"hamming_loss\", \"words_embedding_method\"]]\n",
    "                        .plot(kind=\"bar\", x=\"words_embedding_method\", figsize=(15, 8), rot=0,\n",
    "                                    title=\"Models Performance Sorted by Hamming Loss\"))\n",
    "    performance_plot.title.set_size(20)\n",
    "    performance_plot.set(xlabel=None)\n",
    "    # performance_plot.get_figure().savefig(f\"{RESULTS_PATH}/performance_hamming_loss_plot.png\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_supervised_modeling(questions):\n",
    "    \"\"\"Find the best model using a GridSearchCV hyperoptimization for each words embedding method.\"\"\"\n",
    "    questions_df = DataFrame(questions).head(NUMBER_OF_QUESTIONS_USED_IN_TRAINING)\n",
    "\n",
    "    tags = MultiLabelBinarizer().fit_transform(questions_df['tags'])\n",
    "    questions_df['tags'].to_json(f\"{MODELS_PATH}/tags.json\")\n",
    "\n",
    "    questions_without_tags = questions_df.drop(columns=['tags'], axis=1)\n",
    "\n",
    "    results_df = DataFrame(columns=[\"words_embedding_method\", \"hamming_loss\", \"jaccard_score\"])\n",
    "    models = {}\n",
    "    for words_embedding_method in [\n",
    "        \"Doc2VEC\",\n",
    "        \"BERT\",\n",
    "        \"USE\"\n",
    "    ]:\n",
    "        print(f\"Starting supervised learning of {NUMBER_OF_QUESTIONS_USED_IN_TRAINING} questions with words embedding method:{words_embedding_method}.\\n\")\n",
    "        transformed_text, embedding_time = transform_text(questions_without_tags, words_embedding_method)\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(transformed_text, tags, test_size=0.2, random_state=42)\n",
    "        print(f\"training set size:{len(x_train)}, test set size:{len(x_test)}\\n\")\n",
    "\n",
    "        # XGBClassifier has a Jaccard Score 10x better than the RandomForestClassifier\n",
    "        # Best hyperparameter for 10k questions\n",
    "        default_model = XGBClassifier(n_estimators=100, max_depth=2, device='cuda')\n",
    "        default_hyperparameters = {'estimator__max_depth': range(2, 6)}\n",
    "\n",
    "        fit_start_time = time.time()\n",
    "        grid_search_cv = GridSearchCV(MultiOutputClassifier(estimator=default_model), default_hyperparameters,\n",
    "                                      cv=2,\n",
    "                                      scoring=make_scorer(metrics.jaccard_score, average='samples'),\n",
    "                                      n_jobs=1,  # With cuda it's best to not parallelize jobs or -> cudaErrorMemoryAllocation\n",
    "                                      verbose=3\n",
    "                                      )\n",
    "        \n",
    "        grid_search_cv.fit(x_train, y_train)\n",
    "        best_model = grid_search_cv.best_estimator_\n",
    "\n",
    "        best_parameters = grid_search_cv.best_params_\n",
    "        print(f\"\\nBest Jaccard score:{grid_search_cv.best_score_} with params:{best_parameters}\")\n",
    "\n",
    "        # In case of training of the model\n",
    "        # default_model.fit(x_train, y_train)\n",
    "        # best_model = default_model\n",
    "        \n",
    "        fit_time = np.round(time.time() - fit_start_time, 0)\n",
    "        \n",
    "        models[words_embedding_method] = best_model\n",
    "        predictions_test_y = best_model.predict(x_test)\n",
    "\n",
    "        hamming_loss = metrics.hamming_loss(y_true=y_test, y_pred=predictions_test_y)\n",
    "        jaccard_score = metrics.jaccard_score(y_true=y_test, y_pred=predictions_test_y, average='samples')\n",
    "        print(f\"Hamming loss:{hamming_loss}, jaccard_score:{jaccard_score}\\n\")\n",
    "\n",
    "        # training set size:36000, test set size:9000, XGBClassifier\n",
    "        # Hamming loss:0.0002497610080278267, jaccard_score:0.30443386243386245\n",
    "\n",
    "        results_df.loc[len(results_df)] = [words_embedding_method, hamming_loss, jaccard_score]\n",
    "\n",
    "        send_results_to_mlflow(default_hyperparameters, best_model, hamming_loss, jaccard_score,\n",
    "                               words_embedding_method, x_train, embedding_time, fit_time)\n",
    "\n",
    "    create_results_plot(results_df)\n",
    "\n",
    "    save_best_model(models, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(models, results_df):\n",
    "    \"\"\"Save the best model based on the hamming loss.\"\"\"\n",
    "    best_words_embedding_method = results_df.head(1)['words_embedding_method'].values[0]\n",
    "    joblib.dump(models[best_words_embedding_method], f\"{MODELS_PATH}/best_supervised_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_results_to_mlflow(default_hyperparameters, best_model, hamming_loss, jaccard_score, words_embedding_method,\n",
    "                           x_train, embedding_time, fit_time):\n",
    "    \"\"\"Send data to the MLFlow server.\"\"\"\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(default_hyperparameters)\n",
    "        \n",
    "        mlflow.log_metric(\"hamming_loss\", hamming_loss)\n",
    "        mlflow.log_metric(\"jaccard_score\", jaccard_score)\n",
    "        mlflow.log_metric(\"embedding_time\", embedding_time)\n",
    "        mlflow.log_metric(\"fitting_time\", fit_time)\n",
    "        \n",
    "        mlflow.set_tag(\"Words embedding method\", words_embedding_method)\n",
    "        \n",
    "        signature = infer_signature(x_train, best_model.predict(x_train))\n",
    "        \n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=best_model,\n",
    "            artifact_path=\"supervised-models\",\n",
    "            signature=signature,\n",
    "            input_example=x_train,\n",
    "            registered_model_name=\"XGBoostClassifier\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 17:16:52 INFO mlflow.tracking.fluent: Experiment with name 'Supervised Learning Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting supervised learning script. Please make sure you have a local MLFlow server running, the README file has more information about this.\n",
      "\n",
      "10000 questions loaded from cache.\n",
      "\n",
      "Texts extracted and cleaned.\n",
      "\n",
      "Starting supervised learning of 10000 questions with words embedding method:Doc2VEC.\n",
      "\n",
      "Doc2VEC processing time:54.0s\n",
      "\n",
      "training set size:8000, test set size:2000\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:36:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:36:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:37:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:37:43] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:38:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:38:06] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:38:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:38:16] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ............estimator__max_depth=2;, score=0.001 total time=79.6min\n",
      "[CV 2/2] END ............estimator__max_depth=2;, score=0.001 total time=79.7min\n",
      "[CV 1/2] END ............estimator__max_depth=3;, score=0.001 total time=80.7min\n",
      "[CV 2/2] END ............estimator__max_depth=3;, score=0.002 total time=80.7min\n",
      "[CV 1/2] END ............estimator__max_depth=4;, score=0.002 total time=81.0min\n",
      "[CV 2/2] END ............estimator__max_depth=4;, score=0.001 total time=81.0min\n",
      "\n",
      "Best Jaccard score:0.0017291666666666666 with params:{'estimator__max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [18:43:59] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ............estimator__max_depth=5;, score=0.001 total time=81.1min\n",
      "[CV 1/2] END ............estimator__max_depth=5;, score=0.002 total time=81.1min\n",
      "Hamming loss:0.0007293886058360352, jaccard_score:0.0013416666666666666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 18:45:28 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp7j6ss2c4/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.1', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "Successfully registered model 'XGBoostClassifier'.\n",
      "2024/09/02 18:45:29 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostClassifier, version 1\n",
      "Created version '1' of model 'XGBoostClassifier'.\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:08<00:00,  1.27s/it]\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "2024/09/02 18:45:45 INFO mlflow.tracking._tracking_service.client: 🏃 View run rogue-mink-529 at: http://localhost:8080/#/experiments/514120375666843894/runs/bf99ceec160c463380481a9568018df6.\n",
      "2024/09/02 18:45:45 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:8080/#/experiments/514120375666843894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting supervised learning of 10000 questions with words embedding method:BERT.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725277545.907307  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.051703  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.054968  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.059175  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.062264  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.065088  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.074720  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.077821  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1725277546.080676  183281 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-02 18:45:46.083611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5990 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "Loaded 109,482,240 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/xavier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "BERT processing time:206.0s\n",
      "\n",
      "training set size:8000, test set size:2000\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 2/2] END ..............estimator__max_depth=3;, score=nan total time=   1.9s\n",
      "[CV 2/2] END ..............estimator__max_depth=2;, score=nan total time=   1.9s\n",
      "[CV 1/2] END ..............estimator__max_depth=4;, score=nan total time=   2.2s\n",
      "[CV 1/2] END ..............estimator__max_depth=2;, score=nan total time=   3.1s\n",
      "[CV 2/2] END ..............estimator__max_depth=5;, score=nan total time=   3.0s\n",
      "[CV 1/2] END ..............estimator__max_depth=5;, score=nan total time=   4.1s\n",
      "[CV 2/2] END ..............estimator__max_depth=4;, score=nan total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:23:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "7 fits failed out of a total of 8.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:20] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:20] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 22675456\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x74b58ce2dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x74b58d4a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x74b58cd09f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x74b58d91296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x74b58d92a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x74b58d92b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x74b58d92bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x74b58d17f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x74b58d180564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x74b58ce2dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x74b58d92c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x74b58d17f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x74b58d180564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x74b58d1cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x74b58cd3742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x74b5b126db16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x74b5b126a3ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x74b5b126d0be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:19] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:19] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 14286848\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7c04d222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x7c04d28a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x7c04d2109f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x7c04d2d1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x7c04d2d2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x7c04d2d2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x7c04d2d2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7c04d257f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7c04d2580564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7c04d222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x7c04d2d2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7c04d257f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7c04d2580564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7c04d25cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7c04d213742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x7c04f8059b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x7c04f80563ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x7c04f80590be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:19] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:19] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 1703936\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7e49c442dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x7e49c4aa95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x7e49c4309f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x7e49c4f1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x7e49c4f2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x7e49c4f2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x7e49c4f2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7e49c477f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7e49c4780564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7e49c442dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x7e49c4f2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7e49c477f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7e49c4780564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7e49c47cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7e49c433742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x7e49e84a0b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x7e49e849d3ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x7e49e84a00be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:19] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:19] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 5898240\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7991e102dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x7991e16a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x7991e0f09f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x7991e1b1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x7991e1b2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x7991e1b2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x7991e1b2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7991e137f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7991e1380564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7991e102dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x7991e1b2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7991e137f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7991e1380564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7991e13cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7991e0f3742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x79920502db16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x79920502a3ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x79920502d0be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:50:51] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:50:51] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 98172928\n",
      "- Requested memory: 134217728\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x70272962dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x702729ca95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x702729509f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd21be8) [0x70272a121be8]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22108) [0x70272a122108]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22706) [0x70272a122706]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd28545) [0x70272a128545]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2be91) [0x70272a12be91]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x70272997f196]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x70272962dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x70272a12c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x70272997f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x702729980564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7027299cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x70272953742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x70274d4e1b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x70274d4de3ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x70274d4e10be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:21] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:21] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 31064064\n",
      "- Requested memory: 67108864\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x74788222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x7478828a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x747882109f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd21be8) [0x747882d21be8]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22108) [0x747882d22108]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22706) [0x747882d22706]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd28545) [0x747882d28545]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2be91) [0x747882d2be91]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x74788257f196]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x74788222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x747882d2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x74788257f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x747882580564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7478825cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x74788213742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x7478a7e54b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x7478a7e513ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x7478a7e540be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:49:20] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [18:49:20] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 22675456\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x76d96222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x76d9628a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x76d962109f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x76d962d1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x76d962d2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x76d962d2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x76d962d2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x76d96257f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x76d962580564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x76d96222dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x76d962d2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x76d96257f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x76d962580564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x76d9625cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x76d96213742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x76d987468b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x76d9874653ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x76d9874680be]\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ............estimator__max_depth=3;, score=0.111 total time=37.3min\n",
      "\n",
      "Best Jaccard score:nan with params:{'estimator__max_depth': 2}\n",
      "Hamming loss:0.0006604909680407597, jaccard_score:0.13907142857142857\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 19:47:44 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp75jri0sc/model/model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.5.1', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. \n",
      "Registered model 'XGBoostClassifier' already exists. Creating a new version of this model...\n",
      "2024/09/02 19:47:46 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostClassifier, version 2\n",
      "Created version '2' of model 'XGBoostClassifier'.\n",
      "Downloading artifacts:  86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 6/7 [00:30<00:05,  5.16s/it]\n",
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "2024/09/02 19:48:19 INFO mlflow.tracking._tracking_service.client: 🏃 View run sneaky-shark-901 at: http://localhost:8080/#/experiments/514120375666843894/runs/19944d0818d643d3bd6bce462f03ab3a.\n",
      "2024/09/02 19:48:19 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:8080/#/experiments/514120375666843894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting supervised learning of 10000 questions with words embedding method:USE.\n",
      "\n",
      "USE processing time:37.0s\n",
      "\n",
      "training set size:8000, test set size:2000\n",
      "\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV 2/2] END ..............estimator__max_depth=5;, score=nan total time=   2.1s\n",
      "[CV 2/2] END ..............estimator__max_depth=4;, score=nan total time=   2.1s\n",
      "[CV 1/2] END ..............estimator__max_depth=2;, score=nan total time=   2.3s\n",
      "[CV 1/2] END ..............estimator__max_depth=4;, score=nan total time=  51.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:39:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:39:27] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:39:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:39:41] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "4 fits failed out of a total of 8.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [19:49:02] /workspace/src/c_api/../common/common.h:44: /workspace/src/c_api/../common/device_helpers.cuh: 122: cudaErrorMemoryAllocation: out of memory\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78479922dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x87e181) [0x78479987e181]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a9499) [0x7847998a9499]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xec58a) [0x7847990ec58a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x9276ad) [0x7847999276ad]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x928cb8) [0x784799928cb8]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5c2b6b) [0x7847995c2b6b]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5c92a2) [0x7847995c92a2]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cabbd) [0x7847995cabbd]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [19:49:50] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [19:49:50] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 51118080\n",
      "- Requested memory: 67108864\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7cc45902dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x7cc4596a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x7cc458f09f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd21be8) [0x7cc459b21be8]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22108) [0x7cc459b22108]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd22706) [0x7cc459b22706]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd28545) [0x7cc459b28545]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2be91) [0x7cc459b2be91]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7cc45937f196]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x7cc45902dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x7cc459b2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x7cc45937f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x7cc459380564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7cc4593cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7cc458f3742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x7cc47bb13b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x7cc47bb103ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x7cc47bb130be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [19:49:02] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [19:49:02] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 28966912\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78c2c902dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x78c2c96a95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x78c2c8f09f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x78c2c9b1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x78c2c9b2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x78c2c9b2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x78c2c9b2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x78c2c937f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x78c2c9380564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x78c2c902dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x78c2c9b2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x78c2c937f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x78c2c9380564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x78c2c93cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x78c2c8f3742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x78c2ed07ab16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x78c2ed0773ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x78c2ed07a0be]\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 543, in fit\n",
      "    super().fit(X, Y, sample_weight=sample_weight, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 278, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/multioutput.py\", line 67, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2100, in update\n",
      "    _check_call(\n",
      "  File \"/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [19:49:02] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [19:49:02] /workspace/src/c_api/../common/device_helpers.cuh:400: Memory allocation error on worker 0: std::bad_alloc: cudaErrorMemoryAllocation: out of memory\n",
      "- Free memory: 31064064\n",
      "- Requested memory: 33554432\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x76327942dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x8a95c6) [0x763279aa95c6]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x109f14) [0x763279309f14]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd1296a) [0x763279f1296a]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2a0cc) [0x763279f2a0cc]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2b9ff) [0x763279f2b9ff]\n",
      "  [bt] (6) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2bf84) [0x763279f2bf84]\n",
      "  [bt] (7) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x76327977f196]\n",
      "  [bt] (8) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x763279780564]\n",
      "\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x22dbbc) [0x76327942dbbc]\n",
      "  [bt] (1) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0xd2c154) [0x763279f2c154]\n",
      "  [bt] (2) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x57f196) [0x76327977f196]\n",
      "  [bt] (3) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x580564) [0x763279780564]\n",
      "  [bt] (4) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(+0x5cae68) [0x7632797cae68]\n",
      "  [bt] (5) /home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x76327933742f]\n",
      "  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7b16) [0x76329d687b16]\n",
      "  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x43ef) [0x76329d6843ef]\n",
      "  [bt] (8) /lib/x86_64-linux-gnu/libffi.so.8(ffi_call+0x12e) [0x76329d6870be]\n",
      "\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xavier/Desktop/formation/project_5/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.24437619        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ............estimator__max_depth=2;, score=0.247 total time=52.6min\n",
      "[CV 2/2] END ............estimator__max_depth=3;, score=0.239 total time=52.8min\n",
      "[CV 1/2] END ............estimator__max_depth=3;, score=0.250 total time=53.0min\n",
      "[CV 1/2] END ............estimator__max_depth=5;, score=0.243 total time=53.0min\n",
      "\n",
      "Best Jaccard score:0.24437619047619047 with params:{'estimator__max_depth': 3}\n",
      "Hamming loss:0.0005856878184344604, jaccard_score:0.2783404761904762\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBoostClassifier' already exists. Creating a new version of this model...\n",
      "2024/09/02 20:57:52 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBoostClassifier, version 3\n",
      "Created version '3' of model 'XGBoostClassifier'.\n",
      "Downloading artifacts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:27<00:00,  3.86s/it]\n",
      "2024/09/02 21:00:06 INFO mlflow.tracking._tracking_service.client: 🏃 View run melodic-swan-576 at: http://localhost:8080/#/experiments/514120375666843894/runs/e611cfd271374a86bca6c6fb20073955.\n",
      "2024/09/02 21:00:06 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://localhost:8080/#/experiments/514120375666843894.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Supervised learning now finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting supervised learning script. Please make sure you have a local MLFlow server running, the README file has more information about this.\\n\")\n",
    "remove_last_saved_model()\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:8080\")\n",
    "mlflow.set_experiment(\"Supervised Learning Experiment\")\n",
    "\n",
    "json_questions = load_cached_questions()\n",
    "\n",
    "questions = [{\n",
    "    \"body\": question['body'],\n",
    "    \"tags\": question['tags'],\n",
    "    \"title\": question['title']\n",
    "} for question in json_questions[:NUMBER_OF_QUESTIONS_USED_IN_TRAINING]]\n",
    "\n",
    "print(f\"{len(questions)} questions loaded from cache.\\n\")\n",
    "\n",
    "questions = list(map(extract_and_clean_text, questions))\n",
    "print(\"Texts extracted and cleaned.\\n\")\n",
    "\n",
    "perform_supervised_modeling(questions)\n",
    "\n",
    "print(\"\\nSupervised learning now finished.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
